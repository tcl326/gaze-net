{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ouyangjiahong/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Lambda\n",
    "from keras.engine.topology import Input\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "import time\n",
    "import math\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.engine.topology import Input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import gazenetGenerator as gaze_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global param\n",
    "dataset_path = '../gaze_dataset'\n",
    "learning_rate = 0.0001\n",
    "time_steps = 32\n",
    "num_classes = 6\n",
    "batch_size = 4\n",
    "origin_image_size = 360    # size of the origin image before the cropWithGaze\n",
    "img_size = 128    # size of the input image for network\n",
    "num_channel = 3\n",
    "steps_per_epoch=400\n",
    "epochs=100\n",
    "validation_step=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazeNet():\n",
    "    def __init__(self,learning_rate,time_steps,num_classes,batch_size):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.time_steps = time_steps\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.kernel_size = 15\n",
    "        self.kernel_num = 256\n",
    "        self.gaussian_sigma = 1\n",
    "        self.gaussian_weight = self.create_gaussian_weight()\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_gaussian_weight(self):\n",
    "        kernel_size = self.kernel_size    #same with the shape of the layer before flatten\n",
    "        kernel_num = self.kernel_num\n",
    "        r = (kernel_size - 1) // 2\n",
    "        sigma_2 = float(self.gaussian_sigma * self.gaussian_sigma)\n",
    "        pi = 3.1415926\n",
    "        ratio = 1 / (2*pi*sigma_2)\n",
    "\n",
    "        kernel = np.zeros((kernel_size, kernel_size))\n",
    "        for i in range(-r, r+1):\n",
    "            for j in range(-r, r+1):\n",
    "                tmp = math.exp(-(i*i+j*j)/(2*sigma_2))\n",
    "                kernel[i+r][j+r] = round(tmp, 3)\n",
    "        kernel *= ratio\n",
    "        kernel = np.expand_dims(kernel, axis=2)\n",
    "        kernel = np.tile(kernel, (1,1,kernel_num))\n",
    "        # print(kernel.shape)\n",
    "        return kernel\n",
    "\n",
    "    def create_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        #block 1\n",
    "        model.add(Conv2D(96,(5,5),strides = (2,2),\n",
    "                            padding = 'valid',\n",
    "                            activation = 'relu',\n",
    "                            input_shape = (128,128,3)\n",
    "                            ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "        #block 2\n",
    "        model.add(Conv2D(256,(3,3),padding = 'same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(256,(3,3),padding = 'same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(256,(3,3),padding = 'same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(2,2))\n",
    "\n",
    "        def multiply_constant(input):\n",
    "            for i in range(self.batch_size*self.time_steps):\n",
    "                tmp = tf.multiply(tf.cast(input[i], tf.float32), tf.cast(self.gaussian_weight, tf.float32))\n",
    "                tmp = tf.expand_dims(tmp, 0)\n",
    "                if i == 0:\n",
    "                    res = tmp\n",
    "                else:\n",
    "                    res = tf.concat([res, tmp], 0)\n",
    "            res = tf.reshape(res,[self.batch_size,self.time_steps,\n",
    "                                  self.kernel_size,self.kernel_size,self.kernel_num])\n",
    "            res = tf.reshape(res,[self.batch_size,self.time_steps,\n",
    "                                  self.kernel_size*self.kernel_size*self.kernel_num])\n",
    "            return res\n",
    "\n",
    "        model.add(Lambda(multiply_constant))\n",
    "\n",
    "        def mean_value(input):\n",
    "            return tf.reduce_mean(input,1)\n",
    "\n",
    "        model.add(LSTM(128,return_sequences = True))\n",
    "        model.add(LSTM(6,return_sequences = True))\n",
    "        model.add(Lambda(mean_value))\n",
    "\n",
    "        adam = optimizers.Adam(lr = self.learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        print(model.summary())\n",
    "\n",
    "        return model\n",
    "    \n",
    "#     def train(self):\n",
    "#         # categorical_labels = to_categorical(int_labels, num_classes=None)\n",
    "#         pass\n",
    "\n",
    "#     def load_data(self):\n",
    "#         print(\"Hello world\")\n",
    "\n",
    "#     def save_model_weights(self, folder_path, suffix):\n",
    "#         # Helper function to save your model / weights.\n",
    "#         self.model.save_weights(folder_path + 'weights-' +  str(suffix) + '.h5')\n",
    "#         self.model.save(folder_path + 'model-' +  str(suffix) + '.h5')\n",
    "\n",
    "#     def load_model(self, model_file):\n",
    "#         # Helper function to load an existing model.\n",
    "#         self.model = load_model(model_file)\n",
    "\n",
    "#     def load_model_weights(self,weight_file):\n",
    "#         # Helper funciton to load model weights.\n",
    "#         self.model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropWithGaze(images,gazes,batch_size,time_steps,img_size,num_channel):\n",
    "    img_seq = np.zeros(batch_size,time_steps,img_size,img_size,num_channel)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(time_steps):\n",
    "            x = gaze[1]\n",
    "            y = gaze[2]\n",
    "            image_size = images.shape[2]\n",
    "            assert image_size > img_size\n",
    "            right_bound = min(x+(img_size/2),image_size)\n",
    "            left_bound = max(0,x-(img_size/2))\n",
    "            up_bound = max(0,y-(img_size/2))\n",
    "            down_bound = min(image_size,y+(img_size/2))\n",
    "            img_seq[batch_size,time_steps,:,:,:] = images[batch_size,time_steps,up_bound:down_bound,left_bound:right_bound,:]\n",
    "    return img_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # generate model\n",
    "    gaze_net = GazeNet(learning_rate,time_steps,num_classes,batch_size)\n",
    "    model = gaze_net.model\n",
    "    plot_model(model, to_file='model.png')\n",
    "    print(\"generate model!\")\n",
    "    \n",
    "    # generatr generator\n",
    "    trainGenerator = gaze_gen.GazeDataGenerator(validation_split=0.2)\n",
    "    train_data = trainGenerator.flow_from_directory(dataset_path, subset='training',time_steps=time_steps, \n",
    "                                                    batch_size=batch_size, crop=True, gaussian_std=0.01)\n",
    "    val_data = trainGenerator.flow_from_directory(dataset_path, subset='validation', time_steps=time_steps, \n",
    "                                                  batch_size=batch_size, crop=True, gaussian_std=0.01)\n",
    "    # [img_seq, gaze_seq], output = next(trainGeneratorDirectory)\n",
    "    print(\"fetch data!\")\n",
    "    \n",
    "    # start training\n",
    "    checkpoint = ModelCheckpoint('weight.{epoch:02d}.hdf5', monitor='val_acc', mode='max', period=5)\n",
    "    model.fit_generator(train_data, steps_per_epoch=steps_per_epoch, epochs=epochs, callbacks=[checkpoint], \n",
    "                    validation_data=val_data, validation_step=validation_step, shuffle=False)\n",
    "    print(\"finished training!\")\n",
    "    \n",
    "    \n",
    "#     [img_seq, gaze_seq], output = next(trainGeneratorDirectory)\n",
    "#     img_seq = cropWithGaze(img_seq,gaze_seq,batch_size,time_steps,img_size,num_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 62, 62, 96)        7296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 62, 62, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 31, 31, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 31, 31, 256)       221440    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 31, 31, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 31, 31, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 31, 31, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 31, 31, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 31, 31, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "lambda_9 (Lambda)            (4, 32, 57600)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (4, 32, 128)              29557248  \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (4, 32, 6)                3240      \n",
      "_________________________________________________________________\n",
      "lambda_10 (Lambda)           (4, 6)                    0         \n",
      "=================================================================\n",
      "Total params: 30,972,840\n",
      "Trainable params: 30,971,112\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "generate model!\n",
      "Found 5 Interactions belonging to 6 classes.\n",
      "Found 0 Interactions belonging to 6 classes.\n",
      "fetch data!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_generator() got an unexpected keyword argument 'validation_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-da25ae6f08b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-50f121e1df58>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight.{epoch:02d}.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     model.fit_generator(train_data, steps_per_epoch=steps_per_epoch, epochs=epochs, callbacks=[checkpoint], \n\u001b[0;32m---> 20\u001b[0;31m                     validation_data=val_data, validation_step=validation_step, shuffle=False)\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Keras-2.1.3-py2.7.egg/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() got an unexpected keyword argument 'validation_step'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
